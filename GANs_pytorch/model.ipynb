{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch \n","from torch import nn,optim\n","from torch.utils import data \n","from torchvision import datasets,transforms\n","from torch.utils.data import DataLoader \n","from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt\n","from torchvision.utils import make_grid\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class Discriminator(nn.Module):\n","\n","    def __init__(self, img_dim):\n","        super(Discriminator,self).__init__()\n","\n","        self.disc = nn.Sequential(\n","            nn.Linear(img_dim,128),\n","            nn.LeakyReLU(0.1),\n","            nn.Linear(128,1),\n","            nn.Sigmoid() # Ensure output is 0 or 1 (fake/real)\n","        )\n","\n","    def forward(self,x):\n","        return self.disc(x)\n","\n","\n","class Generator(nn.Module):\n","    # z_dim is noise dimension, img_dim is output img dim\n","    def __init__(self, z_dim, img_dim):\n","        super(Generator,self).__init__()\n","\n","        self.gen = nn.Sequential(\n","            nn.Linear(z_dim, 256),\n","            nn.LeakyReLU(0.1),\n","            nn.Linear(256,img_dim),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self,x):\n","        return self.gen(x)\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","lr = 0.003\n","z_dim = 64\n","image_dim = 28 * 28 * 1\n","batch_size = 32\n","epochs = 10\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["disc = Discriminator(image_dim).to(dev)\n","gen = Generator(z_dim, image_dim).to(dev)\n","fixed_noise = torch.randn((batch_size, z_dim)).to(dev)\n","t = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,),(0.3081,))\n","])\n","\n","dataset = datasets.MNIST(root='./data', download=True, transform=t)\n","loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n","\n","opt_disc = optim.Adam(disc.parameters(), lr=lr)\n","opt_gen = optim.Adam(gen.parameters(), lr=lr)\n","\n","criterion = nn.BCELoss()\n","\n","writer_fake = SummaryWriter(f'runs/GAN_MNIST/fake')\n","writer_real = SummaryWriter(f'runs/GAN_MNIST/real')\n","step = 1\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : [0.0] Loss D : 0.7003, Loss G 0.7469\n","Epoch : [0.1] Loss D : 0.0203, Loss G 7.4318\n","Epoch : [0.2] Loss D : 0.0451, Loss G 12.4789\n","Epoch : [0.3] Loss D : 0.0010, Loss G 13.8596\n","Epoch : [0.4] Loss D : 0.0026, Loss G 9.2070\n","Epoch : [0.5] Loss D : 0.0000, Loss G 37.3625\n","Epoch : [0.6] Loss D : 0.1579, Loss G 20.4912\n","Epoch : [0.7] Loss D : 0.0043, Loss G 43.2655\n","Epoch : [0.8] Loss D : 0.0000, Loss G 57.4588\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-bc395b0379ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlossG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mlossG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/envs/Pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for epoch in range(epochs):\n","    for batch_idx, (real, _) in enumerate(loader):\n","\n","        real = real.view(-1,784).to(dev)\n","        batch_size = real.shape[0]\n","\n","        # Train discriminator\n","        noise = torch.randn((batch_size, z_dim)).to(dev)\n","        fake = gen(noise)\n","\n","        disc_real = disc(real).view(-1)\n","        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n","\n","        disc_fake = disc(fake).view(-1)\n","        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n","\n","        lossD = (lossD_fake + lossD_real) / 2\n","        disc.zero_grad()\n","        lossD.backward(retain_graph=True)\n","        opt_disc.step()\n","\n","        # Train generator\n","        output = disc(fake).view(-1)\n","        lossG = criterion(output, torch.ones_like(output))\n","        gen.zero_grad()\n","        lossG.backward()\n","        opt_gen.step()\n","\n","        if batch_idx == 0 : \n","            print(f'Epoch : [{epoch/epochs}] Loss D : {lossD:.4f}, Loss G {lossG:.4f}')\n","\n","            with torch.no_grad():\n","                fake = gen(fixed_noise).reshape(-1,1,28,28)\n","                real = real.reshape(-1,1,28,28)\n","\n","                fake_grid = make_grid(fake, normalize = True)\n","                real_grid = make_grid(real, normalize = True)\n","\n","                writer_fake.add_image(\n","                    'Mnist fake images', fake_grid, global_step=step\n","                )\n","\n","                writer_real.add_image(\n","                    'Mnist real images', real_grid, global_step=step\n","                )"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"orig_nbformat":2,"kernelspec":{"name":"pytorch","display_name":"Pytorch","language":"python"}}}