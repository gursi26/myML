{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e939f3c51236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/gursi/Desktop/ML/datasets/concrete_data.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Cement              1030 non-null   float64\n",
      " 1   Blast Furnace Slag  1030 non-null   float64\n",
      " 2   Fly Ash             1030 non-null   float64\n",
      " 3   Water               1030 non-null   float64\n",
      " 4   Superplasticizer    1030 non-null   float64\n",
      " 5   Coarse Aggregate    1030 non-null   float64\n",
      " 6   Fine Aggregate      1030 non-null   float64\n",
      " 7   Age                 1030 non-null   int64  \n",
      " 8   Strength            1030 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 72.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
       "       'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cols = df.columns\n",
    "data_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into IVs and DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvals = np.array(df[data_cols[data_cols != 'Strength']], ndmin = 2)\n",
    "yvals = np.array(df['Strength'])\n",
    "xvals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 4723.5913 - val_loss: 276.3214\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 524.6954 - val_loss: 191.4472\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 286.0798 - val_loss: 130.8615\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 205.1317 - val_loss: 108.8109\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 176.8130 - val_loss: 113.7483\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 163.4823 - val_loss: 114.0866\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 151.5880 - val_loss: 88.4282\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 134.9047 - val_loss: 82.7799\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 126.2763 - val_loss: 81.8392\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 118.3645 - val_loss: 78.6328\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 111.8193 - val_loss: 78.7951\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 107.7508 - val_loss: 69.2410\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 102.0485 - val_loss: 70.7551\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 97.4600 - val_loss: 67.6324\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 96.0537 - val_loss: 72.3275\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 92.8210 - val_loss: 69.9318\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 90.9995 - val_loss: 78.1096\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.5428 - val_loss: 69.9885\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 91.7990 - val_loss: 90.0465\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 87.8342 - val_loss: 70.8886\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.4814 - val_loss: 61.9941\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 83.8605 - val_loss: 68.2909\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 85.6183 - val_loss: 66.4394\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 81.0542 - val_loss: 68.4397\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 79.3770 - val_loss: 64.9207\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 73.8655 - val_loss: 70.7718\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 73.6007 - val_loss: 68.5260\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 74.4316 - val_loss: 66.2680\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 78.9964 - val_loss: 72.3228\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 75.5968 - val_loss: 89.1531\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 77.4375 - val_loss: 87.3183\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 73.4881 - val_loss: 72.7262\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 67.3170 - val_loss: 67.5243\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 66.8962 - val_loss: 69.3895\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 70.8967 - val_loss: 60.6664\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 66.6164 - val_loss: 88.9699\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 63.7950 - val_loss: 65.6838\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 63.7213 - val_loss: 73.4244\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 60.4783 - val_loss: 72.8386\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 59.9771 - val_loss: 83.5079\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 59.2472 - val_loss: 73.6301\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 56.6295 - val_loss: 66.4664\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 59.5307 - val_loss: 67.3154\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 60.0420 - val_loss: 79.7070\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 56.2292 - val_loss: 63.4006\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 57.7586 - val_loss: 89.1479\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 55.0292 - val_loss: 72.3629\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 58.6383 - val_loss: 71.0133\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 52.9332 - val_loss: 117.3654\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 56.5100 - val_loss: 78.4760\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 53.1779 - val_loss: 94.0129\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 50.1978 - val_loss: 78.7749\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 49.3574 - val_loss: 88.3576\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 51.5759 - val_loss: 71.5428\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 49.6506 - val_loss: 88.6929\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 49.2900 - val_loss: 91.2766\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 49.3700 - val_loss: 98.4698\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 51.3129 - val_loss: 94.7130\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 47.2262 - val_loss: 60.1802\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 48.1593 - val_loss: 59.9646\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 51.4712 - val_loss: 65.9208\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 47.4561 - val_loss: 126.7762\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 48.7577 - val_loss: 83.0717\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 48.1554 - val_loss: 89.5383\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 46.0362 - val_loss: 99.4284\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 46.1847 - val_loss: 74.4403\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 47.8097 - val_loss: 90.2782\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 47.3603 - val_loss: 60.5215\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 46.4622 - val_loss: 138.0667\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 49.9203 - val_loss: 92.7685\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 46.6505 - val_loss: 81.4298\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 48.5196 - val_loss: 65.2419\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 55.0869 - val_loss: 69.5057\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 45.9747 - val_loss: 103.3208\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 47.4737 - val_loss: 136.7915\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 48.7571 - val_loss: 139.5028\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 46.2820 - val_loss: 84.7729\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 47.2994 - val_loss: 80.6495\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 46.5614 - val_loss: 71.2937\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 44.2580 - val_loss: 111.4970\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 39.9414 - val_loss: 94.2958\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 40.2776 - val_loss: 87.6280\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 50.7007 - val_loss: 74.1270\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 47.2780 - val_loss: 81.1980\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 41.0421 - val_loss: 85.4847\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 39.7969 - val_loss: 81.2343\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 39.7771 - val_loss: 110.4835\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 38.2172 - val_loss: 103.0141\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 37.9819 - val_loss: 86.8972\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 38.3821 - val_loss: 111.3769\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 37.9837 - val_loss: 120.4081\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 39.9265 - val_loss: 98.3574\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 38.4926 - val_loss: 110.1029\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 38.4728 - val_loss: 108.7574\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 40.6944 - val_loss: 121.9202\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 39.1750 - val_loss: 86.1049\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 40.5254 - val_loss: 123.8645\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 37.1810 - val_loss: 126.0086\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 40.0688 - val_loss: 115.4445\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 39.6111 - val_loss: 82.2032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa401335550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape = (8,))) \n",
    "# shape = (number of predictors,)\n",
    "\n",
    "model.add(Dense(50, activation='relu')) \n",
    "model.add(Dense(50, activation='relu')) \n",
    "# 50 refers to number of nodes in layer\n",
    "# Activation refers to activation function\n",
    "\n",
    "model.add(Dense(1)) \n",
    "# Output layer\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "# Optimizer refers to gradient descent, adam is easier since learning rate need not be specified\n",
    "\n",
    "model.fit(xvals, yvals, validation_split = 0.3, epochs = 100, verbose = 1)\n",
    "# 30% of the data for testing, epochs refers to number of runs, verbose is just visualizing runs or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
