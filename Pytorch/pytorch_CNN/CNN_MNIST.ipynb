{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "ml_kernel",
   "display_name": "ML_kernel",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torchvision import datasets as dsets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train = dsets.MNIST(root = './data', train = True, transform=transforms.ToTensor(), download=True)\n",
    "valid = dsets.MNIST(root = './data', train = False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "sample_set_size = 60000\n",
    "indices = torch.randperm(len(train))[:sample_set_size]\n",
    "train_loader = DataLoader(dataset = train, batch_size = batch_size, sampler=SubsetRandomSampler                           (indices))\n",
    "val_loader = DataLoader(dataset = valid, batch_size = 10000, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, out1 = 16, out2 = 32):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=out1, kernel_size=2, padding=3, stride=1)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out1, out_channels=out2, kernel_size=2, padding=3, stride=1)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.linear1 = nn.Linear(10 * 10 * out2, 100)\n",
    "        self.linear2 = nn.Linear(100,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.mp1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.mp2(x)\n",
    "\n",
    "        x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, learning_rate, final_lr, train_loader, val_loader, momentum):\n",
    "\n",
    "    to_plot = []\n",
    "    accuracy = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    num_batches = len(list(train_loader))\n",
    "    print(f'{num_batches} batches per epoch.')\n",
    "\n",
    "    lr_decay = (final_lr - learning_rate) / int((3/4) * epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        opt = optim.SGD(model.parameters(), lr=learning_rate, momentum = momentum)\n",
    "\n",
    "        print('EPOCH : ', epoch + 1)\n",
    "        print('Batch : ', end = '')\n",
    "        counter = 0\n",
    "        mean_loss_list = []\n",
    "        for x,y in train_loader :\n",
    "\n",
    "            opt.zero_grad()\n",
    "            yhat = model.forward(x)\n",
    "\n",
    "            loss = criterion(yhat,y)\n",
    "            mean_loss_list.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if counter % (num_batches/10) == 0 : \n",
    "                print(str(counter) + ' --> ', end = '', flush = True)\n",
    "            counter += 1\n",
    "\n",
    "        mean_loss = mean(mean_loss_list)\n",
    "        to_plot.append(mean_loss)\n",
    "\n",
    "        correct = 0\n",
    "        incorrect = 0\n",
    "\n",
    "        for x,y in val_loader :\n",
    "            model.eval()\n",
    "\n",
    "            yhat = model.forward(x)\n",
    "\n",
    "            for i in range(yhat.shape[0]):\n",
    "                pred = yhat[i].argmax().item()\n",
    "                actual = y[i].item()\n",
    "\n",
    "                if pred == actual :\n",
    "                    correct += 1\n",
    "                else :\n",
    "                    incorrect += 1\n",
    "        \n",
    "        acc = (correct / (correct + incorrect)) * 100\n",
    "        accuracy.append(acc)\n",
    "\n",
    "        print()\n",
    "        print('Mean loss : ', mean_loss)\n",
    "        print(f'Accuracy on test set : {acc} %')\n",
    "        print('-' * 50)\n",
    "\n",
    "        learning_rate = learning_rate - lr_decay\n",
    "\n",
    "    return to_plot, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3000 batches per epoch.\n",
      "EPOCH :  1\n",
      "Batch : 0 --> 300 --> 600 --> 900 --> 1200 --> 1500 --> 1800 --> 2100 --> 2400 --> 2700 --> \n",
      "Mean loss :  0.3003675595802876\n",
      "Accuracy on test set : 97.23 %\n",
      "--------------------------------------------------\n",
      "EPOCH :  2\n",
      "Batch : 0 --> 300 --> 600 --> 900 --> 1200 --> 1500 --> 1800 --> 2100 --> 2400 --> 2700 --> \n",
      "Mean loss :  0.0766290470463476\n",
      "Accuracy on test set : 98.33 %\n",
      "--------------------------------------------------\n",
      "EPOCH :  3\n",
      "Batch : 0 --> 300 --> 600 --> 900 --> 1200 --> 1500 --> 1800 --> 2100 --> 2400 --> 2700 --> \n",
      "Mean loss :  0.05506903864178215\n",
      "Accuracy on test set : 98.11999999999999 %\n",
      "--------------------------------------------------\n",
      "EPOCH :  4\n",
      "Batch : 0 --> 300 --> 600 --> 900 --> 1200 --> 1500 --> 1800 --> 2100 --> 2400 --> 2700 --> \n",
      "Mean loss :  0.04294508469010907\n",
      "Accuracy on test set : 98.57000000000001 %\n",
      "--------------------------------------------------\n",
      "EPOCH :  5\n",
      "Batch : 0 --> 300 --> 600 --> 900 --> 1200 --> 1500 --> 1800 --> 2100 --> 2400 --> 2700 --> \n",
      "Mean loss :  0.03703474378706718\n",
      "Accuracy on test set : 98.50999999999999 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "epochs = 5\n",
    "lr = 0.01\n",
    "momentum = 0.85\n",
    "loss, acc = train_model(model = model, epochs = epochs, learning_rate = lr, final_lr = lr/10, train_loader =                             train_loader, val_loader = val_loader, momentum = momentum)"
   ]
  }
 ]
}