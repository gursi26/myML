{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "colab_nb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QWktU7G4RwS"
      },
      "source": [
        "import torch \n",
        "from torch import nn,optim\n",
        "import torchvision \n",
        "from torchvision import datasets,transforms\n",
        "from torch.utils.data import DataLoader \n",
        "from torch.utils.tensorboard import SummaryWriter "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3uI_JuH--Fa",
        "outputId": "32dfb3f0-574e-446a-835f-090f26c4e9ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTz34SLOHPpX"
      },
      "source": [
        "### Discriminator has no fc layers\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, channels_img, features_d):\n",
        "        super(Discriminator,self).__init__()\n",
        "\n",
        "        # Input shape : N x channels_img x 64 x 64\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1), # 32x32\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            self._block(features_d, features_d*2, 4, 2, 1), # 16x16\n",
        "            self._block(features_d*2, features_d*4, 4, 2, 1), # 8x8\n",
        "            self._block(features_d*4, features_d*8, 4, 2, 1), # 4x4\n",
        "\n",
        "            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=2, padding=0) # 1x1\n",
        "        )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.disc(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5HiqM5vHPpY"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim, channels_img, features_g):\n",
        "        super(Generator,self).__init__()\n",
        "\n",
        "        self.gen = nn.Sequential(\n",
        "\n",
        "            self._block(z_dim, features_g*16, 4, 1, 0), # 4x4\n",
        "            self._block(features_g*16, features_g*8, 4, 2, 1), # 8x8\n",
        "            self._block(features_g*8, features_g*4, 4, 2, 1), # 16x16\n",
        "            self._block(features_g*4, features_g*2, 4, 2, 1), # 32x32\n",
        "\n",
        "            nn.ConvTranspose2d(features_g*2, channels_img, kernel_size=4, stride=2, padding=1), # 64x64\n",
        "            nn.Tanh()\n",
        "\n",
        "        )\n",
        "\n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.gen(x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy3HDvVSHPpY"
      },
      "source": [
        "def initialize_weights(model):\n",
        "    for m in model.modules() :\n",
        "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsrhkCjgHPpZ"
      },
      "source": [
        "def test():\n",
        "    N, in_channels, H, W = 8, 3, 64, 64\n",
        "    z_dim = 100 \n",
        "    x = torch.randn((N, in_channels, H, W))\n",
        "\n",
        "    disc = Discriminator(in_channels, 8)\n",
        "    initialize_weights(disc)\n",
        "    assert disc(x).shape == (N, 1, 1, 1)\n",
        "\n",
        "    gen = Generator(z_dim, in_channels, 8)\n",
        "    initialize_weights(gen)\n",
        "\n",
        "    z = torch.randn((N, z_dim, 1, 1))\n",
        "    assert gen(z).shape == (N, in_channels, H, W)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3T99L9O4RwY"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "LR = 5e-5\n",
        "CHANNELS_IMG = 3\n",
        "FEATURES_D = 64\n",
        "Z_DIM = 100\n",
        "FEATURES_G = 64\n",
        "IMAGE_SIZE = 64\n",
        "step = 0\n",
        "CRITIC_ITERATIONS = 5\n",
        "WEIGHT_CLIP = 0.01"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLRk-wH4HPpZ",
        "outputId": "8f8d8b8a-1e6f-4aa5-82f1-8f684f5fe9f3"
      },
      "source": [
        "dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "t = transforms.Compose([\n",
        "    transforms.Resize(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)])\n",
        "])\n",
        "\n",
        "#data = datasets.MNIST('./data', transform=t, download=True, train=True)\n",
        "data = datasets.ImageFolder('/content/drive/MyDrive/dataset', transform=t)\n",
        "loader = DataLoader(dataset=data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "print(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 5909\n",
            "    Root location: /content/drive/MyDrive/dataset\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=64, interpolation=PIL.Image.BILINEAR)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9JYY7qkHPpa"
      },
      "source": [
        "disc = Discriminator(CHANNELS_IMG, FEATURES_D)\n",
        "disc.load_state_dict(torch.load('/content/drive/MyDrive/WGAN/disc123.pt', map_location=dev))\n",
        "disc.to(dev)\n",
        "#initialize_weights(disc)\n",
        "opt_disc = optim.RMSprop(disc.parameters(), lr = LR)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pprbAXTaHPpa"
      },
      "source": [
        "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_G)\n",
        "gen.load_state_dict(torch.load('/content/drive/MyDrive/WGAN/gen123.pt', map_location=dev))\n",
        "gen.to(dev)\n",
        "#initialize_weights(gen)\n",
        "opt_gen = optim.RMSprop(gen.parameters(), lr = LR)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7BlOXbOHPpa",
        "outputId": "ff82b980-ce1b-43eb-d579-cbfc25f7fa81"
      },
      "source": [
        "fixed_noise = torch.randn((32, Z_DIM, 1, 1)).to(dev)\n",
        "\n",
        "writer_real = SummaryWriter(log_dir='runs/real')\n",
        "writer_fake = SummaryWriter(log_dir='runs/fake')\n",
        "\n",
        "gen.train()\n",
        "disc.train()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (disc): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2)\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2)\n",
              "    )\n",
              "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgaUYdCNwfO2"
      },
      "source": [
        "writer_fake2 = SummaryWriter(log_dir='runs/fake2')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sW4i-FBS5WMY",
        "outputId": "c58f8b55-5fde-440f-ea8f-8c5be70dc0e1"
      },
      "source": [
        "EPOCHS = 200\n",
        "for epoch in range(EPOCHS):\n",
        "    for batch_idx, (real, _) in enumerate(loader):\n",
        "        real = real.to(dev)\n",
        "\n",
        "        for _ in range(CRITIC_ITERATIONS):\n",
        "            noise = torch.randn((BATCH_SIZE, Z_DIM, 1, 1)).to(dev)\n",
        "            fake = gen(noise)\n",
        "\n",
        "            disc_real = disc(real).reshape(-1)\n",
        "            disc_fake = disc(fake).reshape(-1)\n",
        "            loss_D = -(torch.mean(disc_real) - torch.mean(disc_fake))\n",
        "\n",
        "            disc.zero_grad()\n",
        "            loss_D.backward(retain_graph=True)\n",
        "            opt_disc.step()\n",
        "\n",
        "            for p in disc.parameters():\n",
        "                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n",
        "\n",
        "        # train gen\n",
        "        output = disc(fake).reshape(-1)\n",
        "        loss_G = -torch.mean(output)\n",
        "        gen.zero_grad()\n",
        "        loss_G.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "        if batch_idx % 93 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch}/{EPOCHS}] Batch {batch_idx}/{len(loader)} \\\n",
        "                  Loss D: {loss_D:.4f}, loss G: {loss_G:.4f}\"\n",
        "            )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake = gen(fixed_noise)\n",
        "                # take out (up to) 32 examples\n",
        "                img_grid_real = torchvision.utils.make_grid(\n",
        "                    real[:32], normalize=True\n",
        "                )\n",
        "                img_grid_fake = torchvision.utils.make_grid(\n",
        "                    fake[:32], normalize=True\n",
        "                )\n",
        "\n",
        "                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
        "                writer_fake2.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
        "\n",
        "            step += 1\n",
        "\n",
        "    torch.save(disc.state_dict(), f'/content/drive/MyDrive/WGAN/disc{step}.pt')\n",
        "    torch.save(gen.state_dict(), f'/content/drive/MyDrive/WGAN/gen{step}.pt')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/200] Batch 0/93                   Loss D: -0.5874, loss G: 0.5067\n",
            "Epoch [1/200] Batch 0/93                   Loss D: -0.4777, loss G: -0.0545\n",
            "Epoch [2/200] Batch 0/93                   Loss D: -0.4764, loss G: 0.4289\n",
            "Epoch [3/200] Batch 0/93                   Loss D: -0.3972, loss G: 0.3746\n",
            "Epoch [4/200] Batch 0/93                   Loss D: -0.4322, loss G: 0.4815\n",
            "Epoch [5/200] Batch 0/93                   Loss D: -0.4397, loss G: 0.4570\n",
            "Epoch [6/200] Batch 0/93                   Loss D: -0.2532, loss G: 0.1395\n",
            "Epoch [7/200] Batch 0/93                   Loss D: -0.6285, loss G: 0.1018\n",
            "Epoch [8/200] Batch 0/93                   Loss D: -0.5358, loss G: 0.0719\n",
            "Epoch [9/200] Batch 0/93                   Loss D: -0.4468, loss G: 0.3396\n",
            "Epoch [10/200] Batch 0/93                   Loss D: -0.6486, loss G: 0.1174\n",
            "Epoch [11/200] Batch 0/93                   Loss D: -0.7297, loss G: 0.3908\n",
            "Epoch [12/200] Batch 0/93                   Loss D: -0.7818, loss G: 0.3715\n",
            "Epoch [13/200] Batch 0/93                   Loss D: -0.3060, loss G: 0.2116\n",
            "Epoch [14/200] Batch 0/93                   Loss D: -0.1760, loss G: 0.3662\n",
            "Epoch [15/200] Batch 0/93                   Loss D: -0.5068, loss G: 0.4264\n",
            "Epoch [16/200] Batch 0/93                   Loss D: -0.2368, loss G: 0.2372\n",
            "Epoch [17/200] Batch 0/93                   Loss D: -0.0855, loss G: 0.5690\n",
            "Epoch [18/200] Batch 0/93                   Loss D: -0.1594, loss G: 0.3535\n",
            "Epoch [19/200] Batch 0/93                   Loss D: -0.4626, loss G: 0.4169\n",
            "Epoch [20/200] Batch 0/93                   Loss D: -0.1692, loss G: -0.0679\n",
            "Epoch [21/200] Batch 0/93                   Loss D: -0.3216, loss G: 0.2922\n",
            "Epoch [22/200] Batch 0/93                   Loss D: -0.8349, loss G: 0.3900\n",
            "Epoch [23/200] Batch 0/93                   Loss D: -0.8737, loss G: 0.5691\n",
            "Epoch [24/200] Batch 0/93                   Loss D: -0.9010, loss G: 0.4325\n",
            "Epoch [25/200] Batch 0/93                   Loss D: -0.6023, loss G: 0.4053\n",
            "Epoch [26/200] Batch 0/93                   Loss D: -0.3085, loss G: 0.3336\n",
            "Epoch [27/200] Batch 0/93                   Loss D: -0.3889, loss G: 0.3699\n",
            "Epoch [28/200] Batch 0/93                   Loss D: -0.3577, loss G: 0.2101\n",
            "Epoch [29/200] Batch 0/93                   Loss D: -0.0988, loss G: -0.0316\n",
            "Epoch [30/200] Batch 0/93                   Loss D: 0.0362, loss G: -0.3028\n",
            "Epoch [31/200] Batch 0/93                   Loss D: -0.6275, loss G: 0.1596\n",
            "Epoch [32/200] Batch 0/93                   Loss D: -1.1072, loss G: 0.5475\n",
            "Epoch [33/200] Batch 0/93                   Loss D: -0.3293, loss G: 0.1540\n",
            "Epoch [34/200] Batch 0/93                   Loss D: -0.2558, loss G: 0.1205\n",
            "Epoch [35/200] Batch 0/93                   Loss D: -0.6021, loss G: 0.3717\n",
            "Epoch [36/200] Batch 0/93                   Loss D: -0.5028, loss G: 0.4657\n",
            "Epoch [37/200] Batch 0/93                   Loss D: -0.3608, loss G: 0.1081\n",
            "Epoch [38/200] Batch 0/93                   Loss D: -0.3424, loss G: 0.2336\n",
            "Epoch [39/200] Batch 0/93                   Loss D: -0.3960, loss G: 0.4057\n",
            "Epoch [40/200] Batch 0/93                   Loss D: -0.2987, loss G: 0.3752\n",
            "Epoch [41/200] Batch 0/93                   Loss D: -0.2101, loss G: 0.1477\n",
            "Epoch [42/200] Batch 0/93                   Loss D: -0.5861, loss G: 0.4731\n",
            "Epoch [43/200] Batch 0/93                   Loss D: -0.6406, loss G: 0.3176\n",
            "Epoch [44/200] Batch 0/93                   Loss D: -0.1122, loss G: -0.4478\n",
            "Epoch [45/200] Batch 0/93                   Loss D: -0.8444, loss G: 0.3773\n",
            "Epoch [46/200] Batch 0/93                   Loss D: -0.2823, loss G: 0.2779\n",
            "Epoch [47/200] Batch 0/93                   Loss D: -0.1417, loss G: -0.0592\n",
            "Epoch [48/200] Batch 0/93                   Loss D: -1.0252, loss G: 0.5369\n",
            "Epoch [49/200] Batch 0/93                   Loss D: -0.2592, loss G: 0.3953\n",
            "Epoch [50/200] Batch 0/93                   Loss D: -0.3240, loss G: 0.2666\n",
            "Epoch [51/200] Batch 0/93                   Loss D: -0.3872, loss G: 0.1151\n",
            "Epoch [52/200] Batch 0/93                   Loss D: -0.3349, loss G: 0.2519\n",
            "Epoch [53/200] Batch 0/93                   Loss D: 0.0758, loss G: -0.5119\n",
            "Epoch [54/200] Batch 0/93                   Loss D: -0.3909, loss G: 0.2069\n",
            "Epoch [55/200] Batch 0/93                   Loss D: -0.4193, loss G: 0.1178\n",
            "Epoch [56/200] Batch 0/93                   Loss D: -0.5007, loss G: 0.4171\n",
            "Epoch [57/200] Batch 0/93                   Loss D: 0.0371, loss G: 0.6052\n",
            "Epoch [58/200] Batch 0/93                   Loss D: -0.5398, loss G: 0.0503\n",
            "Epoch [59/200] Batch 0/93                   Loss D: -0.1585, loss G: -0.0554\n",
            "Epoch [60/200] Batch 0/93                   Loss D: -0.0970, loss G: 0.5753\n",
            "Epoch [61/200] Batch 0/93                   Loss D: -0.1463, loss G: -0.1677\n",
            "Epoch [62/200] Batch 0/93                   Loss D: -0.2313, loss G: 0.2969\n",
            "Epoch [63/200] Batch 0/93                   Loss D: 0.0218, loss G: 0.5246\n",
            "Epoch [64/200] Batch 0/93                   Loss D: -0.6184, loss G: 0.1562\n",
            "Epoch [65/200] Batch 0/93                   Loss D: -0.5827, loss G: 0.1537\n",
            "Epoch [66/200] Batch 0/93                   Loss D: -0.3843, loss G: 0.3847\n",
            "Epoch [67/200] Batch 0/93                   Loss D: -0.1514, loss G: -0.3145\n",
            "Epoch [68/200] Batch 0/93                   Loss D: -0.3320, loss G: 0.4049\n",
            "Epoch [69/200] Batch 0/93                   Loss D: -0.5526, loss G: 0.4680\n",
            "Epoch [70/200] Batch 0/93                   Loss D: -0.0050, loss G: -0.4593\n",
            "Epoch [71/200] Batch 0/93                   Loss D: -0.2777, loss G: 0.2462\n",
            "Epoch [72/200] Batch 0/93                   Loss D: -0.5654, loss G: 0.4875\n",
            "Epoch [73/200] Batch 0/93                   Loss D: -0.7717, loss G: 0.4197\n",
            "Epoch [74/200] Batch 0/93                   Loss D: -0.0815, loss G: 0.2498\n",
            "Epoch [75/200] Batch 0/93                   Loss D: -0.7162, loss G: 0.2684\n",
            "Epoch [76/200] Batch 0/93                   Loss D: -0.3201, loss G: 0.1513\n",
            "Epoch [77/200] Batch 0/93                   Loss D: 0.0695, loss G: -0.4449\n",
            "Epoch [78/200] Batch 0/93                   Loss D: -1.1229, loss G: 0.5733\n",
            "Epoch [79/200] Batch 0/93                   Loss D: -0.1689, loss G: 0.4417\n",
            "Epoch [80/200] Batch 0/93                   Loss D: -0.3018, loss G: 0.3230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-563b8ba51343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m    150\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}